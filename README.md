# ğŸ“„ PDF Heading Extraction Pipeline

[![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)](https://www.docker.com/)
[![Python](https://img.shields.io/badge/Python-3.9-green.svg)](https://www.python.org/)
[![ML-Powered](https://img.shields.io/badge/ML-Powered-orange.svg)](https://scikit-learn.org/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

> **An advanced machine learning-powered system for extracting structured heading hierarchies from PDF documents with high accuracy and robustness.**

---

## ğŸ¯ Overview

This solution provides a comprehensive PDF heading extraction pipeline that intelligently identifies and classifies document headings into hierarchical structures (H1, H2, H3). Built with a hybrid approach combining rule-based heuristics and machine learning, it handles complex layouts, multi-column documents, tables, and multilingual content.

### âœ¨ Key Features

- **ğŸ¤– Hybrid ML Classification**: Combines rule-based detection with trained machine learning models
- **ğŸ“Š Complex Layout Handling**: Processes multi-column layouts, tables, and nested structures
- **ğŸŒ Multilingual Support**: Handles various scripts and numbering systems
- **âš¡ High Performance**: Optimized for speed with <10s execution per PDF
- **ğŸ³ Containerized**: Ready-to-deploy Docker solution
- **ğŸ“ Lightweight**: Model size <200MB, CPU-only execution

---

## ğŸ—ï¸ Architecture & Approach

### ğŸ“‹ Pipeline Overview

```mermaid
graph TD
    A[PDF Input] --> B[PDF Parser]
    B --> C[Layout Extractor]
    C --> D[Title Identifier]
    D --> E[Heading Detector]
    E --> F[Complex Layout Handler]
    F --> G[ML Classifier]
    G --> H[Level Classifier]
    H --> I[JSON Post-Processor]
    I --> J[Structured Output]
```

### ğŸ§  Core Components

| Component                  | Purpose                      | Key Features                            |
| -------------------------- | ---------------------------- | --------------------------------------- |
| **PDF Parser**             | Text & metadata extraction   | PyMuPDF-based, font analysis            |
| **Layout Extractor**       | Document structure analysis  | Multi-column detection, table filtering |
| **Title Identifier**       | Document title extraction    | Position & formatting heuristics        |
| **Heading Detector**       | Candidate identification     | Font size, formatting, spacing analysis |
| **Complex Layout Handler** | Advanced document processing | TOC extraction, column handling         |
| **Hybrid Classifier**      | ML-powered classification    | Decision tree + rule-based hybrid       |
| **Level Classifier**       | Hierarchical organization    | H1/H2/H3 assignment                     |
| **JSON Post-Processor**    | Output formatting            | Schema validation, hierarchy correction |

### ğŸ” Detection Strategy

#### Rule-Based Heuristics

- **Font Analysis**: Size ratios, bold/italic formatting, font family changes
- **Spatial Analysis**: Vertical gaps, indentation patterns, positioning
- **Content Analysis**: Numbering patterns, capitalization, word count
- **Structural Analysis**: Table filtering, metadata exclusion

#### Machine Learning Features

- Font size ratio to body text
- Character count and average word length
- Vertical spacing before text block
- Relative position on page
- Text formatting indicators
- Numbering depth analysis

#### Advanced Processing

- **Table Detection**: Removes table headers and data rows
- **Multi-column Handling**: Processes complex academic papers
- **TOC Integration**: Leverages table of contents for validation
- **Multilingual Support**: Handles various numbering systems and scripts

---

## ğŸ“š Libraries & Dependencies

### Core Libraries

| Library          | Version  | Purpose                         |
| ---------------- | -------- | ------------------------------- |
| **PyMuPDF**      | 1.23.8   | PDF parsing and text extraction |
| **pdfplumber**   | 0.10.3   | Advanced PDF layout analysis    |
| **pdfminer.six** | 20221105 | Text positioning and metadata   |
| **scikit-learn** | 1.3.2    | Machine learning classification |
| **pytesseract**  | 0.3.10   | OCR for scanned documents       |
| **Pillow**       | 10.1.0   | Image processing support        |
| **numpy**        | 1.24.3   | Numerical computations          |
| **joblib**       | 1.3.2    | Model serialization             |

### System Dependencies

- **Tesseract OCR**: Multi-language text recognition
- **Poppler Utils**: PDF rendering utilities
- **System Libraries**: libgomp1, libglib2.0-0, libsm6, libxext6

---

## ğŸ› ï¸ Model Information

### Machine Learning Model

- **Algorithm**: Decision Tree Classifier (scikit-learn)
- **Features**: 12 engineered features (font, spacing, content-based)
- **Training Data**: 5 sample documents with ground truth annotations
- **Model Size**: ~131KB (well under 200MB limit)
- **Accuracy**: 72.5% cross-validation accuracy

### Feature Engineering

```python
Features = {
    'font_size_ratio': 'Ratio to body text size',
    'char_count': 'Number of characters',
    'avg_word_length': 'Average word length',
    'vertical_gap_before': 'Spacing above text block',
    'relative_y_position': 'Position on page',
    'word_count': 'Number of words',
    'digit_ratio': 'Proportion of digits',
    'punctuation_ratio': 'Punctuation density',
    'numbering_depth': 'Hierarchical numbering level',
    'is_titlecase': 'Title case formatting'
}
```

---

## ğŸš€ Getting Started

### Prerequisites

- Docker (for containerized execution)
- OR Python 3.9+ (for local development)

### ğŸ“¦ Docker Deployment (Recommended)

#### 1. Build the Container

```bash
docker build --platform linux/amd64 -t pdf-heading-extractor .
```

#### 2. Run the Pipeline

```bash
docker run --rm \
  -v $(pwd)/input:/app/input \
  -v $(pwd)/output:/app/output \
  --network none \
  pdf-heading-extractor
```

### ğŸ”§ Local Development

#### 1. Setup Environment

```bash
# Clone repository
git clone https://github.com/Akshay9024/Adobe1A.git
cd Adobe1A

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

#### 2. Install System Dependencies (Ubuntu/Debian)

```bash
sudo apt-get update
sudo apt-get install -y \
    tesseract-ocr \
    tesseract-ocr-eng \
    poppler-utils \
    libgomp1
```

#### 3. Run Pipeline

```bash
python -m src.main_pipeline
```

---

## ğŸ“ Project Structure

```
Adobe1A/
â”œâ”€â”€ ğŸ“ src/                          # Core pipeline modules
â”‚   â”œâ”€â”€ main_pipeline.py             # Main orchestration logic
â”‚   â”œâ”€â”€ pdf_parser.py               # PDF text extraction
â”‚   â”œâ”€â”€ layout_extractor.py         # Document layout analysis
â”‚   â”œâ”€â”€ heading_detector.py         # Heading candidate detection
â”‚   â”œâ”€â”€ hybrid_classifier.py        # ML + rule-based classification
â”‚   â”œâ”€â”€ heading_classifier.py       # Hierarchical level assignment
â”‚   â”œâ”€â”€ complex_layout_handler.py   # Advanced document processing
â”‚   â”œâ”€â”€ title_identifier.py         # Document title extraction
â”‚   â”œâ”€â”€ json_postprocessor.py       # Output formatting
â”‚   â””â”€â”€ evaluation_system.py        # Multilingual & optimization
â”œâ”€â”€ ğŸ“ models/                       # Trained ML models
â”‚   â””â”€â”€ heading_classifier.joblib    # Decision tree classifier
â”œâ”€â”€ ğŸ“ input/                        # Input PDF files
â”œâ”€â”€ ğŸ“ output/                       # Generated JSON outputs
â”œâ”€â”€ ğŸ“ Challenge_1a/                 # Reference dataset
â”‚   â””â”€â”€ sample_dataset/              # Training data
â”œâ”€â”€ ğŸ³ Dockerfile                    # Container configuration
â”œâ”€â”€ ğŸ“‹ requirements.txt              # Python dependencies
â”œâ”€â”€ ğŸ”§ docker-entrypoint.sh         # Container entry point
â”œâ”€â”€ ğŸ§ª train_model.py               # Model training script
â””â”€â”€ ğŸ“– README.md                    # This documentation
```

---

## ğŸ¯ Usage Examples

### Input/Output Format

#### Input

```
input/
â”œâ”€â”€ document1.pdf
â”œâ”€â”€ document2.pdf
â””â”€â”€ document3.pdf
```

#### Output

```json
{
  "title": "Document Title",
  "outline": [
    {
      "level": "H1",
      "text": "Chapter 1: Introduction",
      "page": 0
    },
    {
      "level": "H2",
      "text": "1.1 Background",
      "page": 1
    },
    {
      "level": "H3",
      "text": "1.1.1 Problem Statement",
      "page": 2
    }
  ]
}
```

### Command Line Usage

#### Process Single PDF

```python
from src.main_pipeline import HeadingExtractionPipeline

pipeline = HeadingExtractionPipeline()
result = pipeline.extract_headings("document.pdf")
print(json.dumps(result, indent=2))
```

#### Batch Processing

```python
pipeline = HeadingExtractionPipeline()
pipeline.process_batch("input_dir/", "output_dir/")
```

---

## âš¡ Performance & Constraints

### System Requirements

- **Memory**: 16GB RAM recommended
- **CPU**: 8 cores, x86_64 architecture
- **Storage**: Minimal (~500MB including dependencies)
- **Network**: No internet access required

### Performance Metrics

- **Execution Time**: <10 seconds per PDF
- **Model Size**: 131KB (0.0006% of 200MB limit)
- **Accuracy**: 72.5% on validation set
- **Throughput**: ~6 PDFs per minute

### Constraints Compliance

- âœ… **Platform**: linux/amd64 compatible
- âœ… **Execution Time**: <10s per document
- âœ… **Model Size**: <200MB (actual: 131KB)
- âœ… **Network**: Offline execution
- âœ… **Resources**: CPU-only, no GPU required

---

## ğŸ§ª Testing & Validation

### Model Training

```bash
# Retrain model with new data
python train_model.py
```

### Testing Pipeline

```bash
# Test with sample documents
python test_ml_integration.py
```

### Performance Evaluation

The system has been tested on diverse document types:

- âœ… Academic papers (multi-column layouts)
- âœ… Technical manuals (complex hierarchies)
- âœ… Business reports (mixed formatting)
- âœ… Presentation slides (PowerPoint exports)
- âœ… Forms and applications (structured layouts)

---

## ğŸ”§ Configuration

### Environment Variables

```bash
PYTHONUNBUFFERED=1          # Disable output buffering
PYTHONPATH=/app             # Python module path
OMP_NUM_THREADS=8           # OpenMP thread count
TESSDATA_PREFIX=/usr/share/tesseract-ocr/4.00/tessdata
```

### Pipeline Options

```python
pipeline = HeadingExtractionPipeline(
    use_multiprocessing=False,  # Disable for Docker
    use_ml_classifier=True,     # Enable ML classification
    ml_model_path="models/heading_classifier.joblib"
)
```

---

## ğŸ† Key Achievements

- **ğŸ¯ High Accuracy**: 72.5% classification accuracy on diverse documents
- **âš¡ Fast Processing**: <10s execution time per PDF
- **ğŸŒ Multilingual**: Supports various languages and scripts
- **ğŸ—ï¸ Robust Architecture**: Handles complex layouts and edge cases
- **ğŸ“¦ Production Ready**: Containerized with proper error handling
- **ğŸ”§ Maintainable**: Modular design with clear separation of concerns

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/enhancement`)
3. Commit changes (`git commit -am 'Add new feature'`)
4. Push to branch (`git push origin feature/enhancement`)
5. Create Pull Request

---

## Acknowledgments

- **PyMuPDF Team**: Excellent PDF processing library
- **scikit-learn Community**: Robust machine learning framework
- **Tesseract OCR**: Reliable text recognition
- **Docker Community**: Containerization platform

---

<div align="center">

**Built with â¤ï¸h for robust PDF document analysis**

</div>
